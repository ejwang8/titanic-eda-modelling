{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25eae3f8",
   "metadata": {},
   "source": [
    "## How can we predict survival on the Titanic?\n",
    "\n",
    "Predict survival on the Titanic using passenger features like age, fare, class, and more. This project includes exploratory data analysis (EDA), feature engineering, and testing multiple classification models.\n",
    "\n",
    "### Guiding Questions\n",
    "- Which features are correlated with survival?\n",
    "- Can we accurately predict survival with a simple model?\n",
    "- Which model performs best on this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130df2e",
   "metadata": {},
   "source": [
    "1. Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score # did i use this?\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ad6ae",
   "metadata": {},
   "source": [
    "2. Load and Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f607ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('titanic/train.csv')\n",
    "test_df = pd.read_csv('titanic/test.csv')\n",
    "print(f\"Passengers in train set: {train_df.shape[0]}\\nPassengers in test set: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f15ce5",
   "metadata": {},
   "source": [
    "We have 891 rows in the training set and 418 in the test set â€” a roughly 7:3 ratio.\n",
    "\n",
    "Will explore the types in each columns, better understand/see examples of embarked and cabin values to see how to engineer featuers, look for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024c3ce",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "| Column | dtype | Description |\n",
    "|----------|----------|----------|\n",
    "| PassengerId  | int64  | unique passenger  |\n",
    "| Survived  | int64  | binary value of survival outcome (0, 1)  |\n",
    "| Pclass  | int64  | class (1, 2, 3)  |\n",
    "| Name  | object  | string value for name --> to quantify in feature engineering, we deduced title from this as well as name length  |\n",
    "| Sex  | object  | sex (\"male\", \"female\")  |\n",
    "| Age  | float64  | passenger's age at time of ?  |\n",
    "| SibSp  | int64  | sibling/spouse #?  |\n",
    "| Parch  | int64  | parents/children #?  |\n",
    "| Ticket  | object?  | ?  |\n",
    "| Fare  | float64  | ticket cost LOGGED ITTTTTTT |\n",
    "| Cabin  | object  | cabin identifer of format letter + number (e.g. C85, C123, B42, C148) - from research, letter corresponds to deck which we engineered our own feature from this  |\n",
    "| Embarked  | object  | port passenger boarded from? ('S', 'C', 'Q' which correspond to Southampton, Cherbourg, Queenstown)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"].str[0].unique()\n",
    "train_df[\"Cabin\"].str[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2aaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860068b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeedb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b24bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c93929",
   "metadata": {},
   "source": [
    "We see that the Age, Fare, Cabin, Embarked????? have null values to be dealt with/cleaned in the train and test datset\n",
    "\n",
    "Next, let's look at statistic summaries of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b649f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c756f52",
   "metadata": {},
   "source": [
    "We see train and test df have similar summary statistics. from first glance, all columns seem to have reasonable means and min/max (pclass 1-3 all valid, age in right range, # sibs or parch as well as fare all seem reasonable with no outright impossible valus/outliers - though fare seems to be very right skewed)\n",
    "\n",
    "we will look into each variable distribution more to see if any single varaible distribution can be preprocessed or cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218b0b0",
   "metadata": {},
   "source": [
    "### Data Cleaning & Feature Engineering\n",
    "\n",
    "Examples:\n",
    "- Visualize survival by class, sex, age, family, fare\n",
    "- Show correlations (heatmap, groupby stats)\n",
    "- Fill missing Age and Fare with median.\n",
    "- Create binary columns from Sex, Embarked, Deck.\n",
    "- Engineer features like Fare_log, Has_Cabin (derived from cabin), or grouped titles (ended up not using grouped titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot for each categorical attributes cumulative\n",
    "#AND sns.countplot for each categorical attributes by died/survived\n",
    "    #survived, sex, embarked\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 3), nrows=1, ncols=3)\n",
    "sns.countplot(x=\"Survived\", data=train_df, ax=axes[0])\n",
    "sns.countplot(x=\"Sex\", data=train_df, ax=axes[1])\n",
    "sns.countplot(x=\"Embarked\", data=train_df, ax=axes[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46d8e3",
   "metadata": {},
   "source": [
    "We see that majority perished in titanic, there were more male aboard, and most embarked from 'S' in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50363eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot for numerical attirbutes\n",
    "#pclass, age, sibsp, parch, fare\n",
    "\n",
    "fig1, axes1 = plt.subplots(figsize=(8, 3), nrows=1, ncols=3)\n",
    "fig2, axes2 = plt.subplots(figsize=(8, 3), nrows=1, ncols=2)\n",
    "sns.countplot(x=\"Pclass\", data=train_df, ax=axes1[0])\n",
    "sns.histplot(x=\"Age\", data=train_df, ax=axes1[1])\n",
    "sns.countplot(x=\"SibSp\", data=train_df, ax=axes1[2])\n",
    "sns.countplot(x=\"Parch\", data=train_df, ax=axes2[0])\n",
    "sns.histplot(x=\"Fare\", data=train_df, ax=axes2[1])\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa437cd8",
   "metadata": {},
   "source": [
    "majority of passengers in 3rd class, then 1st, then 2nd. age seems normally distributed (???). sib sp and parch seem similar right skewed most had 0. fare seems very right skewed so may need to be normalized--used log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96130ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare_log'] = np.log1p(train_df['Fare'])  # log1p avoids log(0) errors\n",
    "sns.histplot(x=\"Fare_log\", data=train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0a723",
   "metadata": {},
   "source": [
    "for managing cabin, since it's a string we'll just set to \"Unknown\" for fillna. it seems that one thing we can feature engineeri extract the first letter which is the \"deck\" that a passenger stayed on so\n",
    "- deck fillna with \"Unknown\"\n",
    "- we will create a \"deck\" which is the first letter of the \"cabin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill deck nan with \"U\"\n",
    "train_df['Cabin'].fillna('Unknown', inplace=True)\n",
    "train_df[\"Deck\"] = train_df[\"Cabin\"].str[0] # U = unknown\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2aa283",
   "metadata": {},
   "source": [
    "feature engineering for NAME -- ended up not using this bc not helpful\n",
    "- the \"name\" is of format \"[surname], [title], [first and middle etc name/nicknames]\" which we can deduce \"surname length\", \"title\" and \"first name length\" from which i imagine are more meaningful features than name - so i will deduce \"surname\" and \"title\" and then drop calculate teh lenght of the remaining first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Surname Length\"] = train_df[\"Name\"].str.split(',').str[0].str.len()\n",
    "train_df[\"Title\"] = train_df[\"Name\"].str.split(',').str[1].str.split(' ').str[1]\n",
    "train_df[\"First Name Length\"] = train_df[\"Name\"].str.split(',').str[1].str.split(\". \", regex=False).str[1].str.len()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52513389",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4143cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Title\"] == \"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d6cfc",
   "metadata": {},
   "source": [
    "categorizing the titles into meaningful categories that takes into account marital status which could equate to class as well as how rare the titels are (e.g. \"the\" is for \"the Countess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd414d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\n",
    "    \"Mr.\": \"Mr\",\n",
    "    \"Mrs.\": \"Mrs\",\n",
    "    \"Miss.\": \"Miss\",\n",
    "    \"Ms.\": \"Miss\",       # Unmarried woman (modern)\n",
    "    \"Mlle.\": \"Miss\",     # French for Miss\n",
    "    \"Mme.\": \"Mrs\",       # French for Mrs\n",
    "    \"Master.\": \"Master\", # Usually boys under 12\n",
    "    \"Dr.\": \"Rare\",       # Ambiguous â€” could be male or female\n",
    "    \"Rev.\": \"Rare\",\n",
    "    \"Major.\": \"Rare\",\n",
    "    \"Col.\": \"Rare\",\n",
    "    \"Capt.\": \"Rare\",\n",
    "    \"Sir.\": \"Rare\",\n",
    "    \"Lady.\": \"Rare\",\n",
    "    \"Don.\": \"Rare\",\n",
    "    \"Jonkheer.\": \"Rare\",\n",
    "    \"the\": \"Rare\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30629b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Title\"] = train_df[\"Title\"].map(title_mapping)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b3785",
   "metadata": {},
   "source": [
    "make sex into binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ecc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sex'] = train_df['Sex'].map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec6fa8",
   "metadata": {},
   "source": [
    "ok now help me apply get_dummy prior to correlation heatmap to see if embarked, deck, or title have meaning\n",
    "\n",
    "and then drop name and ticket and cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb07af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Deck', hue='Survived', data=train_df)\n",
    "plt.ylim(top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb7695",
   "metadata": {},
   "source": [
    "--> decision to bucket! (movea fter correlation? or something)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262c56",
   "metadata": {},
   "source": [
    "then add dummy data for categories like embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=[\"Deck\", \"Embarked\", \"Title\"])\n",
    "train_df.drop(axis=1, columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "print(train_df.columns)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d379750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to answer 'Which features are correlated with survival?' correlation plot\n",
    "\n",
    "corr = train_df.corr()\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84202432",
   "metadata": {},
   "source": [
    "DROPPING\n",
    "\n",
    "**Embarked_Q** â†’ near 0 correlation\n",
    "\n",
    "**Deck_A, Deck_G, Deck_T** â†’ too rare or no predictive value so dropping\n",
    "\n",
    "**Title_*** â†’ only Mr, Miss, Mrs were correlated which is redundant with Sex\n",
    "\n",
    "**Surname Length** 0 correlation\n",
    "\n",
    "**Deck_U**\n",
    "\n",
    "ADDING IN/TWEAKING\n",
    "\n",
    "**Decks B-E** were high survival decks --> add a bucket feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['High Survival Deck'] = (train_df['Deck_B']) | (train_df['Deck_C']) | (train_df['Deck_D']) | (train_df['Deck_E'])\n",
    "train_df.drop(axis=1, columns=['Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_T', 'Embarked_Q', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Surname Length'], inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try again \n",
    "\n",
    "corr = train_df.corr()\n",
    "plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb69045",
   "metadata": {},
   "source": [
    "given our EDA, age is not super correlated variable so prob fine to set to mean of train_df (can also try ommitting, and maybe setting to mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15913c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill age na values\n",
    "train_df['Age'].fillna(train_df['Age'].mean(), inplace=True) # here I tried both median and mean - mean fared better\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7ae49",
   "metadata": {},
   "source": [
    "train is all set! now let's fun it to get validation accuracy acros smodels to find best one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfe7da",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "- 5 models: Logistic Regression, Decision Tree, Random Forest, KNN, Naive Bayes\n",
    "- Optionally: SVM, Gradient Boosting, or Perceptron\n",
    "- Compare accuracy, precision, recall, AUC\n",
    "- Pick a best model + explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general code to get CV accuracy of model\n",
    "\n",
    "def evaluate_model(model, X, y, cv=5, scoring='accuracy'):\n",
    "    \"\"\"Evaluate a model using cross-validation.\"\"\"\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    print(f\"{model} Mean: {np.mean(scores)})\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Fare_log', 'First Name Length', 'Embarked_C', 'Embarked_S', 'High Survival Deck']]\n",
    "y_train = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier()\n",
    "dectree = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "svm = SVC()\n",
    "gradboost = GradientBoostingClassifier()\n",
    "percep = Perceptron()\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(logreg, X_train, y_train)\n",
    "evaluate_model(rf, X_train, y_train)\n",
    "evaluate_model(dectree, X_train, y_train)\n",
    "evaluate_model(knn, X_train, y_train)\n",
    "evaluate_model(nb, X_train, y_train)\n",
    "evaluate_model(svm, X_train, y_train)\n",
    "evaluate_model(gradboost, X_train, y_train)\n",
    "evaluate_model(percep, X_train, y_train)\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd9feb",
   "metadata": {},
   "source": [
    "random forest is da best so we go w it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf987e",
   "metadata": {},
   "source": [
    "need to get test_df ship shape for running models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg code\n",
    "y_train = train_df['Survived']\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Fare_log'] = np.log1p(X_test['Fare'])  # log1p avoids log(0) errors\n",
    "X_test['Fare_log'].fillna(X_test['Fare_log'].mean(), inplace=True) # here I tried both median and mean - mean fared better\n",
    "X_test['Cabin'].fillna('Unknown', inplace=True)\n",
    "X_test[\"Deck\"] = X_test[\"Cabin\"].str[0] # U = unknown\n",
    "X_test[\"Surname Length\"] = X_test[\"Name\"].str.split(',').str[0].str.len()\n",
    "X_test[\"First Name Length\"] = X_test[\"Name\"].str.split(',').str[1].str.split(\". \", regex=False).str[1].str.len()\n",
    "X_test['Sex'] = X_test['Sex'].map({'male':0, 'female':1})\n",
    "X_test = pd.get_dummies(X_test, columns=[\"Embarked\"])\n",
    "X_test['High Survival Deck'] = (X_test['Deck'].isin(['B', 'C', 'D', 'E'])).astype(int)\n",
    "X_test = X_test[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Fare_log', 'First Name Length', 'Embarked_C', 'Embarked_S', 'High Survival Deck']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn --> add this to enviro\n",
    "# log reg!\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('titanic/gender_submission.csv')\n",
    "submission['Survived'] = y_pred\n",
    "submission # answer to 'Can we accurately predict survival with a simple model?' ys got to 77.x%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/final_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b1d1c8",
   "metadata": {},
   "source": [
    "### 1) Logistic Regression model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 2) Decision Tree model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 3) Random Forest\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 4) KNN model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 5) Naive Bayes model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 6) SVM model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 7) Gradient Boosting model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]\n",
    "\n",
    "### 8) Perceptron model\n",
    "\n",
    "- description high level w figs (read articles / watch vids)\n",
    "- pros and cons in general and for this dataset\n",
    "\n",
    "[writeup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698dc7e",
   "metadata": {},
   "source": [
    "### Final Evaluation\n",
    "\n",
    "- Confusion matrix, F1, ROC curve\n",
    "- Feature importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439cc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933298b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to answer 'Which model performs best on this dataset?'ArithmeticError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a0f75",
   "metadata": {},
   "source": [
    "[write up too]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69074a5",
   "metadata": {},
   "source": [
    "### Wrap-up\n",
    "- Final thoughts, takeaways\n",
    "- What youâ€™d do next with more time/data\n",
    "- References or inspiration sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253721e6",
   "metadata": {},
   "source": [
    "[writeup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44ce6e",
   "metadata": {},
   "source": [
    "# References\n",
    "- Titanic - Machine Learning from Disaster [https://www.kaggle.com/competitions/titanic/data]\n",
    "- Titanic (wikipedia) [https://en.wikipedia.org/wiki/Titanic]\n",
    "- cleaning data [https://www.youtube.com/watch?v=cWf08xuSqdU&ab_channel=DataGeekismyname]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae69482",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
